{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3420f355",
   "metadata": {},
   "source": [
    "# Praca domowa z ML numer 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2583ac0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/tomczj/ML24_25/blob/main/Multi_Layer_Perc/homework_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3b104c",
   "metadata": {},
   "source": [
    "##### UWAGA: W poniższym pliku zamieszczono przerywniki tak, aby zapobiec przypadkowemu odpaleniu się funckji, które się bardzo długo liczą (tj. generowanie animacji)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59173b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7566bb4e",
   "metadata": {},
   "source": [
    "#### Funkcje pomocnicze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaa3b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funckja służąca do przeskalowania obrazku na różne skale szarości\n",
    "\n",
    "def rescale_0_1(imgs):\n",
    "    min_vals = imgs.amin(dim=(1,2,3), keepdim=True)\n",
    "    max_vals = imgs.amax(dim=(1,2,3), keepdim=True)\n",
    "    return (imgs - min_vals) / (max_vals - min_vals + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ustalamy seed\n",
    "torch.manual_seed(439669)\n",
    "np.random.seed(439669)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e917515",
   "metadata": {},
   "source": [
    "## Trenowanie sieci neuronowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f043bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='./data',\n",
    "                                      train=True,\n",
    "                                      download=True,\n",
    "                                      transform=None)\n",
    "\n",
    "(trainset.data.numpy().mean()/255.0, trainset.data.numpy().std()/255.0)\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [ torchvision.transforms.ToTensor(),\n",
    "      torchvision.transforms.Normalize((0.1307), (0.3081))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data',\n",
    "                                      train=True,\n",
    "                                      download=True,\n",
    "                                      transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=2048,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data',\n",
    "                                     train=False,\n",
    "                                     download=True,\n",
    "                                     transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=1,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4363453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear1 = torch.nn.Linear(1*28*28, 1024)\n",
    "        self.linear2 = torch.nn.Linear(1024, 2048)\n",
    "        self.linear3 = torch.nn.Linear(2048, 256)\n",
    "        self.linear4 = torch.nn.Linear(256, 10)\n",
    "        self.dropout = torch.nn.Dropout(0.05)\n",
    "\n",
    "    def forward(self, x):              # B, 1, 28, 28\n",
    "        x = self.flatten(x)            # B, 784\n",
    "        x = self.relu(self.linear1(x)) # B, 1024\n",
    "        x = self.relu(self.linear2(x)) # B, 2048\n",
    "        x = self.relu(self.linear3(x)) # B, 256\n",
    "        x = self.linear4(x)            # B, 10\n",
    "        x = self.dropout(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c00a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Working on {device}\")\n",
    "\n",
    "net = MLP().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), 0.0001)\n",
    "\n",
    "net.train() \n",
    "for epoch in range(8):\n",
    "\n",
    "    for batch, data in enumerate(trainloader):\n",
    "        batch_inputs, batch_labels = data\n",
    "\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_outputs = net(batch_inputs)  \n",
    "\n",
    "        loss = torch.nn.functional.cross_entropy(batch_outputs, batch_labels, reduction = \"mean\")\n",
    "        print(\"epoch:\", epoch, \"batch:\", batch, \"current batch loss:\", loss.item())\n",
    "        loss.backward()     \n",
    "        optimizer.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a413a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "good = 0\n",
    "wrong = 0\n",
    "\n",
    "net.eval()     \n",
    "with torch.no_grad():  \n",
    "    for batch, data in enumerate(testloader): \n",
    "        datapoint, label = data\n",
    "\n",
    "        prediction = net(datapoint.to(device))                 \n",
    "        classification = torch.argmax(prediction)  \n",
    "\n",
    "        if classification.item() == label.item():\n",
    "            good += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "\n",
    "print(\"accuracy = \", good/(good+wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4518a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zapisanie do pliku jakby były problemy\n",
    "\n",
    "torch.save(net.state_dict(), \"mlp_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89640ac0",
   "metadata": {},
   "source": [
    "### Ładujemy wytrenowany już wcześniej model\n",
    "######  - jakby były problemy w powyższym kodem to wystarczy pobrać plik pth z githuba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear1 = torch.nn.Linear(1*28*28, 1024)\n",
    "        self.linear2 = torch.nn.Linear(1024, 2048)\n",
    "        self.linear3 = torch.nn.Linear(2048, 256)\n",
    "        self.linear4 = torch.nn.Linear(256, 10)\n",
    "        self.dropout = torch.nn.Dropout(0.05)\n",
    "\n",
    "    def forward(self, x):              # B, 1, 28, 28\n",
    "        x = self.flatten(x)            # B, 784\n",
    "        x = self.relu(self.linear1(x)) # B, 1024\n",
    "        x = self.relu(self.linear2(x)) # B, 2048\n",
    "        x = self.relu(self.linear3(x)) # B, 256\n",
    "        x = self.linear4(x)            # B, 10\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fbbfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#korzystamy z cpu lub gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#definiujemy model\n",
    "net = MLP()\n",
    "\n",
    "#pobieramy wytenowany model\n",
    "net.load_state_dict(torch.load(\"mlp_model.pth\"))\n",
    "net.to(device)\n",
    "\n",
    "#zamrażamy wagi\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b846627",
   "metadata": {},
   "source": [
    "## Część I - neural network dreaming (jedna cyfra)\n",
    "Poniżej znajduje się kod, który przekształca początkowe obrazki będące szumem (o rozkładzie Gaussa) w obrazy przypominające cyfry ze zbioru danych **MNIST**. Proces ten przebiega poprzez przepuszczenie zaszumionych obrazków przez wcześniej wytrenowaną sieć neuronową, a następnie iteracyjną zmianę wartości pikseli (czyli ich odcieni szarości od białego do czarnego) za pomocą algorytmu *gradient descent*. Celem tej optymalizacji jest uzyskanie obrazków, które sieć rozpozna jako konkretne cyfry z MNIST — mimo że początkowo są to jedynie losowe zakłócenia.\n",
    "\n",
    "W poniższym kodzie zastosowaliśmy odrazu element regularyzacyjny, to znaczy uwględniliśmy dodatkowo funkcję starty $l_2$, aby wymusić na sieci neuronowej to jak dużo szumu dopuszczamy w finalnym obrazku. Aby to dobrze zobrazować to wybrano następujące $\\lambda \\in \\{0, 0.01, 0.1, 1.0, 10.0\\}$, gdzie przypadek $\\lambda = 0$ oznacza, że w obliczeniach nie uwględniono czynnika regularyzacyjnego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432f67bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [0, 0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "# ilość kroków, które wykonamy\n",
    "steps = 7500\n",
    "#learnin rate\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec38ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy listę, która będzie przechowywać obrazki uzyskane dla różnych wartości lambdy\n",
    "all_images = []\n",
    "\n",
    "# przechodzimy przez kolejne wartości lambda_l2\n",
    "for lambda_l2 in lambdas:\n",
    "    # ustalamy docelowe etykiety od 0 do 9\n",
    "    targets = torch.arange(10, device=device)\n",
    "\n",
    "    # inicjalizujemy 10 losowych obrazków (po jednym dla każdej cyfry)\n",
    "    dr_images = torch.randn((10, 1, 28, 28), device=device, requires_grad=True)\n",
    "\n",
    "    img_opt = torch.optim.Adam([dr_images], lr=lr)\n",
    "\n",
    "    # wykonujemy odpowiednią liczbę kroków optymalizacji\n",
    "    for step in range(steps):\n",
    "        img_opt.zero_grad()\n",
    "\n",
    "        # przepuszczamy obrazki przez sieć\n",
    "        logits = net(dr_images)\n",
    "\n",
    "        # liczymy stratę: cross-entropy + regularyzacja L2\n",
    "        loss = F.cross_entropy(logits, targets) + lambda_l2 * dr_images.pow(2).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        img_opt.step()\n",
    "\n",
    "    # przekształcamy obrazki do zakresu [0,1] i przenosimy na CPU\n",
    "    final_images = rescale_0_1(dr_images.detach().cpu())\n",
    "    all_images.append((lambda_l2, final_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77168469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rysujemy obrazki\n",
    "\n",
    "fig, axes = plt.subplots(len(lambdas), 10, figsize=(20, 10))\n",
    "for row_idx, (lambda_val, images) in enumerate(all_images):\n",
    "    for col_idx in range(10):\n",
    "        ax = axes[row_idx, col_idx]\n",
    "\n",
    "        ax.imshow(images[col_idx, 0], cmap='gray')\n",
    "        if row_idx == 0:\n",
    "            ax.set_title(f\"{col_idx}\")\n",
    "\n",
    "        if col_idx == 0:\n",
    "            ax.set_ylabel(f\"λ={lambda_val:.2e}\", rotation=0, labelpad=30)\n",
    "        ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a34b8",
   "metadata": {},
   "source": [
    "Zauważmy, że w przypadku $\\lambda = 0$ cyfry, które otrzymaliśmy w nie przypominają dokładnie cyfr ze zbioru MNIST (chociaż można dostrzec przebijające się szczegóły) - nawet przy przepuszczeniu zaszumionych obrazków ponad 5000 razy przez wytrenowaną wcześniej sieć neuronową. Można wysnuć wniosek, że sieć neuronowa dostrzega jakieś dodatkowe szczegóły, których ludzkie oko być może nie dostrzega wcześniej - oczekujemy pełnej cyfry, aby móc stwierdzić co widać na obrazku. \n",
    "\n",
    "Dzieje się tak, ponieważ sieć neuronowa uczy się dodatkowego szumu i małych szczegółów, które pozwalają jej później sklasyfikować dany obrazek jako poszczególna cyfra z dużym przekonaniem.\n",
    "\n",
    "Warto tutaj również zwrócić uwagę na przypadki gdy dodano czynnik regulryzujący do funckji straty. Mianowicie dodano element `lambda_l2 * dr_images.pow(2).mean()`, który ma kontrolować jak sieć patrzy na szum na obrazku. W szczególności, możemy zauważyć, że wraz ze wzrostem parametru $\\lambda_{l2}$ obserwujemy wyostyrzenie się obrazu - dużo lepiej widać na nim cyfry, które chcieliśmy uzyskać. Wynika to z tego, że nakładamy ograniczenie ile szumu chcemy - wysokie $\\lambda$ oznacza wyższą karę za dopuszczenie szumu.\n",
    "\n",
    "Warto również dodać, że cyfry wygenerowany w powyższy sposób są poprawnie klasyfikowane przez sieć neuronową.\n",
    "\n",
    "Poniżej możemy obejrzeć animację, jak zmieniane są piksele na zaszumionych obrazkach oraz z jakim przekonaniem siec neuronowa klasyfikuje wybraną liczbę. Co ciekawe, wytrenowana sieć neuronowa potrafi sklasyfikować daną cyfrę dużo szybciej niż pojawią się pierwsz większe szczegóły, co widać na animacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf387c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/tomczj/ML24_25/main/Multi_Layer_Perc/all_lambdas_animation.gif\"\n",
    "HTML(f\"<img src='{url}' alt='Animacja dla wszystkich lambda' />\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff61d7e",
   "metadata": {},
   "source": [
    "## Część II – *Neural Network Dreaming* (dwie cyfry)\n",
    "\n",
    "Poniżej znajduje się kod, który przekształca początkowe obrazki będące szumem (o rozkładzie Gaussa) w obrazy przypominające cyfry ze zbioru danych **MNIST**. Proces ten przebiega poprzez przepuszczenie zaszumionych obrazków przez wcześniej wytrenowaną sieć neuronową, a następnie iteracyjną zmianę wartości pikseli (czyli ich odcieni szarości od białego do czarnego) za pomocą algorytmu *gradient descent*. Celem tej optymalizacji jest uzyskanie obrazków, które sieć rozpozna jako konkretne cyfry z MNIST — mimo że początkowo są to jedynie losowe zakłócenia.\n",
    "\n",
    "W tej części zadania chcemy jednak uzyskać bardziej złożony efekt: zamiast jednej cyfry, dążymy do wygenerowania obrazka, który będzie przypominał **jednocześnie dwie różne cyfry**. Innymi słowy, modyfikujemy szum w taki sposób, aby po optymalizacji sieć neuronowa rozpoznała na nim zarówno jedną, jak i drugą wybraną cyfrę (mniej więcej - chodzi o to, że prawdopodobieństwa powinny być mniej więcej równe).\n",
    "\n",
    "Aby osiągnąć ten efekt, modyfikujemy funkcję straty. Zamiast jednej etykiety prawdziwej, rozważamy dwie: pierwotną (`targets`) oraz zamienioną (`targets_changes`). Funkcja straty przyjmuje wówczas postać:\n",
    "\n",
    "##### `loss = 0.5 * F.cross_entropy(logits, targets) + 0.5 * F.cross_entropy(logits, targets_changes) + lambda_l2 * dr_images.pow(2).mean()`\n",
    "\n",
    "\n",
    "Idea z taką modyfikacją funkcji straty polega na przypisaniu równych wag dla dwóch różnych etykiet jednocześnie (wagi 0.5) tak aby wymusić minmalizacje funkcji straty w punkcie, gdzie sieć neuronowa sklasyfikuje obrazek jako dwie różne cyfry (z pewną dokładnością.)\n",
    "\n",
    "\n",
    "W poniższym kodzie zastosowaliśmy odrazu element regularyzacyjny, to znaczy uwględniliśmy dodatkowo funkcję starty $l_2$, aby wymusić na sieci neuronowej to jak dużo szumu dopuszczamy w finalnym obrazku. Aby to dobrze zobrazować to wybrano następujące $\\lambda \\in \\{0, 0.01, 0.1, 1.0, 10.0\\}$, gdzie przypadek $\\lambda = 0$ oznacza, że w obliczeniach nie uwględniono czynnika regularyzacyjnego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ca54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "target_digit = 5        # cyfra, którą animujemy (np. 5)\n",
    "other_digit = 8         # druga cyfra, do której chcemy się jednocześnie zbliżyć\n",
    "\n",
    "net.eval()\n",
    "\n",
    "#Zmienne celu: targets i targets_changes\n",
    "targets = torch.arange(10, device=device)\n",
    "targets_changes = targets.clone()\n",
    "targets_changes[target_digit] = other_digit\n",
    "targets_changes[other_digit] = target_digit\n",
    "\n",
    "# Tytuły dla wizualizacji – podmienione cyfry z \"&\"\n",
    "titles = [f\"{i}\" for i in range(10)]\n",
    "titles[target_digit] = f\"{target_digit} & {other_digit}\"\n",
    "titles[other_digit] = f\"{other_digit} & {target_digit}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315122d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_images = []\n",
    "\n",
    "# Pętla po różnych lambda\n",
    "for lambda_l2 in lambdas:\n",
    "    dr_images = torch.randn((10, 1, 28, 28), device=device, requires_grad=True)\n",
    "    img_opt = torch.optim.Adam([dr_images], lr=lr)\n",
    "\n",
    "    for step in range(steps):\n",
    "        img_opt.zero_grad()\n",
    "        logits = net(dr_images)\n",
    "        loss = 0.5 * F.cross_entropy(logits, targets) + \\\n",
    "               0.5 * F.cross_entropy(logits, targets_changes) + \\\n",
    "               lambda_l2 * dr_images.pow(2).mean()\n",
    "        loss.backward()\n",
    "        img_opt.step()\n",
    "\n",
    "    final_images = dr_images.detach().cpu()\n",
    "    final_images = (final_images - final_images.min()) / (final_images.max() - final_images.min() + 1e-5)\n",
    "    all_final_images.append(final_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda125f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(lambdas), 10, figsize=(20, 10))\n",
    "for row, (lambda_l2, imgs) in enumerate(zip(lambdas, all_final_images)):\n",
    "    for col in range(10):\n",
    "        ax = axes[row, col]\n",
    "        ax.imshow(imgs[col, 0], cmap='gray')\n",
    "        if row == 0:\n",
    "            ax.set_title(titles[col])\n",
    "        ax.axis('off')\n",
    "    axes[row, 0].set_ylabel(f\"λ = {lambda_l2}\", rotation=0, labelpad=30, size='large', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e007d2",
   "metadata": {},
   "source": [
    "Jak widać na powyższym obrazku, rzeczywiście na jednym obrazku możemy znaleźć dwie cyfry jednocześnie - chodzi o cyfry 5 i 8. Wobec tego można powiedzieć, że obrana metoda generowania cyfr w sposób jak w poleceniu podziałała. Jak już wspomniano we wcześniejszym zadaniu, wraz ze wzrostem parametru $\\lambda$ obserwujemy wzrost jakości obrazu, to znaczy cyfry są dużo lepiej widoczne i przypominają te ze zbioru MNIST. Poniżej możemy obejrzeć animacje, na której pokazane jest jak zmieniają się piksele na zaszumionym obrazku z dwoma liczbami oraz jak wygląda proces klasyfikacji obrazka. Warto tutaj zauważyć, że istotnie prawdopodobieństwo przypisanie dla naszej podówjnej cyfry wartości 5 lub 8 jest zbliżone. Co ciekawe, wytrenowana sieć neuronowa potrafi sklasyfikować daną cyfrę dużo szybciej niż pojawią się pierwsz większe szczegóły, co widać na animacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d4033c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='https://raw.githubusercontent.com/tomczj/ML24_25/main/Multi_Layer_Perc/double_digit_animation.gif' alt='Animacja dla wszystkich lambda - double digit' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/tomczj/ML24_25/main/Multi_Layer_Perc/double_digit_animation.gif\"\n",
    "HTML(f\"<img src='{url}' alt='Animacja dla wszystkich lambda - double digit' />\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"Ta linijka ma na celu zapobieganiu odpalenia animacji, które się bardzo długo liczą\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7215badd",
   "metadata": {},
   "source": [
    "## Animacje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ef7c2",
   "metadata": {},
   "source": [
    "#### Animacja do zadania pierwszego wraz z różnymi parametrami regularyzującymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc188b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definiujemy model\n",
    "net = MLP()\n",
    "\n",
    "#pobieramy wytenowany model\n",
    "net.load_state_dict(torch.load(\"mlp_model.pth\"))\n",
    "net.to(device)\n",
    "\n",
    "#zamrażamy wagi\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07429896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Konfiguracja\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "target_digit = 6  # wybrana cyfra, którą będziemy animować\n",
    "steps = 1501      # liczba kroków optymalizacji\n",
    "lr = 0.003        # learning rate\n",
    "lambdas = [0, 0.01, 0.1, 1.0, 10.0]  # lista różnych wartości lambda\n",
    "\n",
    "#Przygotowanie modelu\n",
    "net.eval()\n",
    "\n",
    "#Struktury danych do przechowywania ramek dla każdej lambdy\n",
    "all_image_frames = []       # lista: dla każdej lambdy -> lista obrazków\n",
    "all_probability_frames = [] # lista: dla każdej lambdy -> lista prawdopodobieństw\n",
    "\n",
    "#Optymalizacja osobno dla każdej lambdy\n",
    "for lambda_l2 in lambdas:\n",
    "    # tworzymy losowe obrazki i optymalizator\n",
    "    dr_images = torch.randn((10, 1, 28, 28), device=device, requires_grad=True)\n",
    "    targets = torch.arange(10, device=device)\n",
    "    optimizer = torch.optim.Adam([dr_images], lr=lr)\n",
    "\n",
    "    # listy do przechowywania wyników dla tej lambdy\n",
    "    image_frames = []\n",
    "    probability_frames = []\n",
    "\n",
    "    # pętla optymalizacji\n",
    "    for step in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        logits = net(dr_images)\n",
    "        loss = F.cross_entropy(logits, targets) + lambda_l2 * dr_images.pow(2).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            img = dr_images[target_digit].detach().cpu().squeeze().numpy()\n",
    "            img = (img - img.min()) / (img.max() - img.min() + 1e-5)  # skalujemy do [0, 1]\n",
    "            probs = F.softmax(logits[target_digit], dim=0).cpu().numpy()\n",
    "            image_frames.append(img)\n",
    "            probability_frames.append(probs)\n",
    "\n",
    "    # zapisujemy wyniki do zbiorczych list\n",
    "    all_image_frames.append(image_frames)\n",
    "    all_probability_frames.append(probability_frames)\n",
    "\n",
    "#Przygotowanie wykresu\n",
    "fig, axes = plt.subplots(len(lambdas), 2, figsize=(10, 10))\n",
    "\n",
    "def update_all(frame_idx):\n",
    "    for row_idx in range(len(lambdas)):\n",
    "        ax_img = axes[row_idx, 0]\n",
    "        ax_bar = axes[row_idx, 1]\n",
    "\n",
    "        # czyścimy stare dane\n",
    "        ax_img.clear()\n",
    "        ax_bar.clear()\n",
    "\n",
    "        # pobieramy odpowiednią klatkę z obrazkiem i wykresem słupkowym\n",
    "        img = all_image_frames[row_idx][frame_idx]\n",
    "        probs = all_probability_frames[row_idx][frame_idx]\n",
    "\n",
    "        # obrazek\n",
    "        ax_img.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "        ax_img.set_title(f\"λ={lambdas[row_idx]} | krok {frame_idx}\")\n",
    "        ax_img.axis('off')\n",
    "\n",
    "        # wykres słupkowy\n",
    "        ax_bar.bar(np.arange(10), probs)\n",
    "        ax_bar.set_ylim(0, 1)\n",
    "        ax_bar.set_title(\"Prawdopodobieństwo klasyfikacji jako odpowiednia cyfra\")\n",
    "        ax_bar.set_xticks(np.arange(10))\n",
    "\n",
    "#Tworzymy animację\n",
    "ani = FuncAnimation(fig, update_all, frames=steps, interval=50)\n",
    "plt.tight_layout()\n",
    "ani.save(\"all_lambdas_animation.gif\", writer=PillowWriter(fps=40))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f201865d",
   "metadata": {},
   "source": [
    "#### Animacja do zadania drugiego wraz z różnymi parametrami regularyzującymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c1bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Konfiguracja\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "target_digit = 5         # cyfra, którą animujemy (np. 5)\n",
    "other_digit = 8          # druga cyfra, do której chcemy się jednocześnie zbliżyć\n",
    "steps = 1501      # liczba kroków optymalizacji\n",
    "lr = 0.005        # learning rate\n",
    "lambdas = [0, 0.01, 0.1, 1.0, 10.0]  # lista różnych wartości lambda\n",
    "\n",
    "net.eval()\n",
    "\n",
    "#Zmienne celu: targets i targets_changes (np. 5 i 8)\n",
    "targets = torch.arange(10, device=device)\n",
    "targets_changes = targets.clone()\n",
    "targets_changes[target_digit] = other_digit\n",
    "targets_changes[other_digit] = target_digit\n",
    "\n",
    "all_image_frames = []\n",
    "all_probability_frames = []\n",
    "\n",
    "#Pętla po różnych lambdach\n",
    "for lambda_l2 in lambdas:\n",
    "    # tworzymy losowe obrazki i optymalizator\n",
    "    dr_images = torch.randn((10, 1, 28, 28), device=device, requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([dr_images], lr=lr)\n",
    "\n",
    "    # listy na klatki tej lambdy\n",
    "    image_frames = []\n",
    "    probability_frames = []\n",
    "\n",
    "    # pętla optymalizacji\n",
    "    for step in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        logits = net(dr_images)\n",
    "        loss = (\n",
    "            0.5 * F.cross_entropy(logits, targets)\n",
    "            + 0.5 * F.cross_entropy(logits, targets_changes)\n",
    "            + lambda_l2 * dr_images.pow(2).mean()\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # zapisujemy klatkę z obrazkiem i softmaxem\n",
    "        with torch.no_grad():\n",
    "            img = dr_images[target_digit].detach().cpu().squeeze().numpy()\n",
    "            img = (img - img.min()) / (img.max() - img.min() + 1e-5)  # skalowanie do [0, 1]\n",
    "            probs = F.softmax(logits[target_digit], dim=0).cpu().numpy()\n",
    "            image_frames.append(img)\n",
    "            probability_frames.append(probs)\n",
    "\n",
    "    # zapisujemy wyniki dla tej lambdy\n",
    "    all_image_frames.append(image_frames)\n",
    "    all_probability_frames.append(probability_frames)\n",
    "\n",
    "# Przygotowanie wykresów\n",
    "fig, axes = plt.subplots(len(lambdas), 2, figsize=(10, 2.5 * len(lambdas)))\n",
    "\n",
    "def update_all(frame_idx):\n",
    "    for row_idx in range(len(lambdas)):\n",
    "        ax_img = axes[row_idx, 0]\n",
    "        ax_bar = axes[row_idx, 1]\n",
    "\n",
    "        # czyścimy stare dane\n",
    "        ax_img.clear()\n",
    "        ax_bar.clear()\n",
    "\n",
    "        # pobieramy odpowiednie dane\n",
    "        img = all_image_frames[row_idx][frame_idx]\n",
    "        probs = all_probability_frames[row_idx][frame_idx]\n",
    "\n",
    "        # obrazek\n",
    "        ax_img.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "        ax_img.set_title(f\"λ={lambdas[row_idx]} | krok {frame_idx}\")\n",
    "        ax_img.axis('off')\n",
    "\n",
    "        # wykres słupkowy\n",
    "        ax_bar.bar(np.arange(10), probs)\n",
    "        ax_bar.set_ylim(0, 1)\n",
    "        ax_bar.set_title(\"Prawdopodobieństwo klasyfikacji jako odpowiednia cyfra\")\n",
    "        ax_bar.set_xticks(np.arange(10))\n",
    "\n",
    "#Tworzymy animację\n",
    "ani = FuncAnimation(fig, update_all, frames=steps, interval=50)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Zapis do pliku\n",
    "ani.save(\"double_digit_animation.gif\", writer=PillowWriter(fps=40))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
